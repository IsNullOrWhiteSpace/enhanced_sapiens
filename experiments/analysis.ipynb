
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n",
    "\n",
    "# set seaborn theme\n",
    "sns.set_theme()\n",
    "\n",
    "# set seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# set seaborn palette\n",
    "sns.set_palette(\"tab10\")\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data of the control group are expected to be in `data/control/*.json`\n",
    "- Data of the treatment group are expected to be in `data/*.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trials(pattern='data/*.json'):\n",
    "    \"\"\"Load trials from json files into a pandas dataframe.\"\"\"\n",
    "    trials = []\n",
    "    for path in glob.glob(pattern):\n",
    "        with open(path) as f:\n",
    "            trial = json.load(f)\n",
    "            trial['filename'] = path\n",
    "            trials.append(trial)\n",
    "\n",
    "    if len(trials) == 0:\n",
    "        raise ValueError('No trials found')\n",
    "        \n",
    "    df = pd.json_normalize(trials)\n",
    "\n",
    "    # convert to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a not too strict definition of success for now. \n",
    "We accept trials that have reached 'Served' and 'BowlWithCerelAndMilk' states since the task is not explicitly about serving the meal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def succeeded(trial):\n",
    "    \"\"\"Return True if trial succeeded.\"\"\"\n",
    "    return trial['analysis.final_state_name'] in ['Served', 'BowlWithCerealAndMilk']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load control data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_df = load_trials(pattern='data/control/*.json')\n",
    "control_df['succeeded'] = control_df.apply(succeeded, axis=1)\n",
    "control_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of reached accepting state - center bars\n",
    "control_df['succeeded'].astype(float).hist(bins=2, align='mid', rwidth=0.5)\n",
    "# false/true labels\n",
    "plt.xticks([0.25, 0.75], ['false', 'true'])\n",
    "plt.xlabel('reached accepting state')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load new trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_df = load_trials(pattern='data/*.json')\n",
    "treatment_df['succeeded'] = treatment_df.apply(succeeded, axis=1)\n",
    "treatment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of reached accepting state - center bars\n",
    "treatment_df['succeeded'].astype(float).hist(bins=2, align='mid', rwidth=0.5)\n",
    "# false/true labels\n",
    "plt.xticks([0.25, 0.75], ['false', 'true'])\n",
    "plt.xlabel('reached accepting state')\n",
    "plt.ylabel('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot with analysis.tokens.prompt_tokens as x-axis and \n",
    "# analysis.tokens.completion_tokens as y-axis  \n",
    "# analysis.reached_accepting_state as color - True: green, False: red\n",
    "# analysis.tokens.total_tokens as size\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=treatment_df,\n",
    "    x='analysis.tokens.prompt_tokens',\n",
    "    y='analysis.tokens.completion_tokens',\n",
    "    hue='succeeded',\n",
    "    size='analysis.tokens.total_tokens',\n",
    "    sizes=(10, 100),\n",
    "    alpha=0.8,\n",
    "    palette=['red', 'green'],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the states the model reached\n",
    "failed_trials_df = treatment_df[treatment_df['succeeded'] == False]\n",
    "failed_trials_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore one of the trials that didn't reach an accepting state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the first failed trial\n",
    "failed_trial_filename = failed_trials_df.iloc[0]['filename']\n",
    "failed_trial_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filename = treatment_df.copy()\n",
    "df_filename.set_index('filename', inplace=True)\n",
    "\n",
    "df_filename.loc[failed_trial_filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for evt in df_filename.loc[failed_trial_filename]['trace.events']:\n",
    "    match evt['type']:\n",
    "        case 'Start':\n",
    "            print(f\"==== [start] task: {evt['task']}\")\n",
    "        case 'End':\n",
    "            print(f\"==== [end] reason = {evt}\")\n",
    "        case 'ToolInvocationSucceeded':\n",
    "            print(f\"====[tool] tool = {evt['tool_name']}\")\n",
    "            print(\"==[tool] input = \\n\", \"\\n\".join(evt['assistant_message']))\n",
    "            print(\"==[tool] output = \\n\", \"\\n\".join(evt['result']['output']))\n",
    "        case 'ToolInvocationFailed':\n",
    "            print(f\"====[tool] tool = {evt['tool_name']}\")\n",
    "            print(\"==[tool] input = \\n\", \"\\n\".join(evt['tool_input']))\n",
    "            print(\"==[tool] error = \\n\", \"\\n\".join(evt['error']))        \n",
    "        case _:\n",
    "            print(f\"==== [other] {evt}\")\n",
    "       \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian A/B testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using https://www.pymc.io/projects/examples/en/latest/case_studies/bayesian_ab_testing_introduction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "\n",
    "from scipy.stats import bernoulli, expon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 4000\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "\n",
    "plotting_defaults = dict(\n",
    "    bins=50,\n",
    "    kind=\"hist\",\n",
    "    textsize=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BetaPrior:\n",
    "    alpha: float\n",
    "    beta: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BinomialData:\n",
    "    trials: int\n",
    "    successes: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversionModelTwoVariant:\n",
    "    def __init__(self, priors: BetaPrior):\n",
    "        self.priors = priors\n",
    "\n",
    "    def create_model(self, data: List[BinomialData]) -> pm.Model:\n",
    "        trials = [d.trials for d in data]\n",
    "        successes = [d.successes for d in data]\n",
    "        with pm.Model() as model:\n",
    "            p = pm.Beta(\"p\", alpha=self.priors.alpha, beta=self.priors.beta, shape=2)\n",
    "            obs = pm.Binomial(\"y\", n=trials, p=p, shape=2, observed=successes)\n",
    "            reluplift = pm.Deterministic(\"reluplift_b\", p[1] / p[0] - 1)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(control_df, treatment_df):\n",
    "    \"\"\"Prepare data for the conversion model from the trials.\"\"\"\n",
    "\n",
    "    # dataframe with two columns: 'orig' and 'new'\n",
    "    # each row contains the number of trials and successes for the variant\n",
    "    data = pd.DataFrame(columns=['control', 'treatment'], dtype=int)\n",
    "\n",
    "    # iterate over the trials\n",
    "    control_ = control_df['succeeded'].astype(float).agg(['sum', 'count'])\n",
    "    treatment_ = treatment_df['succeeded'].astype(float).agg(['sum', 'count'])\n",
    "\n",
    "    data['control'] = [control_['count'], control_['sum']]\n",
    "    data['treatment'] = [treatment_['count'], treatment_['sum']]\n",
    "\n",
    "    # set the index\n",
    "    data.index = ['trials', 'successes']\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(control_df, treatment_df)\n",
    "data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scenario_twovariant(\n",
    "    raw_data: pd.DataFrame,\n",
    "    weak_prior: BetaPrior,\n",
    "    strong_prior: BetaPrior,\n",
    ") -> None:\n",
    "    variants = raw_data.columns\n",
    "    assert len(variants) == 2\n",
    "    \n",
    "    data = [BinomialData(**raw_data[v].to_dict()) for v in variants]\n",
    "    with ConversionModelTwoVariant(priors=weak_prior).create_model(data):\n",
    "        trace_weak = pm.sample(draws=5000)\n",
    "    with ConversionModelTwoVariant(priors=strong_prior).create_model(data):\n",
    "        trace_strong = pm.sample(draws=5000)\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 1, figsize=(7, 7), sharex=True)\n",
    "    az.plot_posterior(trace_weak.posterior[\"reluplift_b\"], ax=axs[0], **plotting_defaults)\n",
    "    axs[0].set_title(f\"{weak_prior}\", fontsize=10)\n",
    "    axs[0].axvline(x=0, color=\"red\")\n",
    "    az.plot_posterior(trace_strong.posterior[\"reluplift_b\"], ax=axs[1], **plotting_defaults)\n",
    "    axs[1].set_title(f\"{strong_prior}\", fontsize=10)\n",
    "    axs[1].axvline(x=0, color=\"red\")\n",
    "    fig.suptitle(f\"{variants[1]} vs. {variants[0]} Rel Uplift\")\n",
    "    return trace_weak, trace_strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test with fake data\n",
    "#\n",
    "# weak_prior = ConversionModelTwoVariant(BetaPrior(alpha=100, beta=100))\n",
    "# strong_prior = ConversionModelTwoVariant(BetaPrior(alpha=1000, beta=1000))\n",
    "\n",
    "# with weak_prior.create_model(data=[BinomialData(1,1), BinomialData(1,1)]):\n",
    "#     weak_prior_predictive = pm.sample_prior_predictive(samples=10000, return_inferencedata=False)\n",
    "\n",
    "# with strong_prior.create_model(data=[BinomialData(1,1), BinomialData(1,1)]):\n",
    "#     strong_prior_predictive = pm.sample_prior_predictive(samples=10000, return_inferencedata=False)\n",
    "\n",
    "\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(7, 7), sharex=True)\n",
    "# az.plot_posterior(weak_prior_predictive[\"reluplift_b\"], ax=axs[0], **plotting_defaults)\n",
    "# axs[0].set_title(f\"B vs. A Rel Uplift Prior Predictive, {weak_prior.priors}\", fontsize=10)\n",
    "# axs[0].axvline(x=0, color=\"red\")\n",
    "# az.plot_posterior(strong_prior_predictive[\"reluplift_b\"], ax=axs[1], **plotting_defaults)\n",
    "# axs[1].set_title(f\"B vs. A Rel Uplift Prior Predictive, {strong_prior.priors}\", fontsize=10)\n",
    "# axs[1].axvline(x=0, color=\"red\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_prior = BetaPrior(alpha=100, beta=100)\n",
    "strong_prior = BetaPrior(alpha=10000, beta=10000)\n",
    "trace_weak, trace_strong = run_scenario_twovariant(data, \n",
    "                                                   weak_prior=weak_prior,\n",
    "                                                   strong_prior=strong_prior)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textrm{relative\\_uplift} = (\\textrm{treatment} - \\textrm{control}) / \\textrm{control}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sapiens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}